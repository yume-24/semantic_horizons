Music cognition is the interdisciplinary study of how we perceive, process, and produce music. In my research, I focus on auditory prediction—how the brain anticipates musical structure in real time. We use EEG and MEG to measure how violations of musical expectation elicit neural responses, particularly the mismatch negativity (MMN) and P300 components. There’s growing evidence that musical training enhances cognitive functions like working memory, attentional control, and even linguistic syntax processing. This isn’t just correlational—longitudinal studies suggest causality, especially when training starts early in development. We’re also examining the emotional dynamics of music. Music elicits powerful affective states, and we’re trying to understand how structural features—tempo, mode, harmonic progression—interact with personal memory and cultural associations to produce emotional experiences. From a computational angle, we’re using probabilistic models like IDyOM (Information Dynamics of Music) to simulate expectation formation in listeners. These models help us quantify 'surprise' and 'predictability' in music and compare them to neural data. Another exciting area is embodied cognition—how rhythm and meter are tied to movement. Motor regions in the brain are activated even when people passively listen to rhythm. This has led to promising music-based interventions for motor disorders like Parkinson’s. Music cognition shows us that music isn’t just entertainment—it’s a window into brain function, emotion, culture, and human connection.